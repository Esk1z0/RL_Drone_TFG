{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "import enviroments_package\n",
    "import gymnasium\n",
    "\n",
    "\n",
    "world_dir = \"/Users/jeste/Desktop/Clase/TFG/drone_tfg_juanes/simulation_package/worlds/my_frst_webots_world.wbt\"\n",
    "json_take_off = \"/Users/jeste/Desktop/Clase/TFG/drone_tfg_juanes/configs/reward_package_config/takeoff.json\"\n",
    "json_basic = \"/Users/jeste/Desktop/Clase/TFG/drone_tfg_juanes/configs/reward_package_config/basic_no_roll.json\"\n",
    "json_use_motors = \"/Users/jeste/Desktop/Clase/TFG/drone_tfg_juanes/configs/reward_package_config/motors_use.json\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-09T12:39:56.247447700Z",
     "start_time": "2024-11-09T12:39:56.206449600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "import gymnasium\n",
    "from stable_baselines3.common.env_util import SubprocVecEnv\n",
    "from enviroments_package import RemoveKeyObservationWrapper, ScaleRewardWrapper, ScaleActionWrapper\n",
    "\n",
    "\n",
    "num_envs = 4  # Define el número de entornos que se van a crear\n",
    "\n",
    "def make_env():\n",
    "    def _init():\n",
    "        # Crea el entorno base\n",
    "        env = gymnasium.make('drone_tfg_juanes/Drone-v1', simulation_path=world_dir, reward_json_path=json_use_motors, no_render=False)\n",
    "\n",
    "        # Aplica los wrappers necesarios\n",
    "        env = RemoveKeyObservationWrapper(env, remove_keys=[\"camera\", \"gps\"])\n",
    "        env = ScaleRewardWrapper(env, scale_factor=0.1)\n",
    "        env = ScaleActionWrapper(env, in_low=-1, in_high=1, out_low=0, out_high=576)\n",
    "        return env\n",
    "    return _init\n",
    "\n",
    "\n",
    "env = SubprocVecEnv([make_env() for _ in range(num_envs)])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-09T12:40:05.460454500Z",
     "start_time": "2024-11-09T12:39:56.223448700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from stable_baselines3.common.callbacks import BaseCallback\n",
    "\n",
    "\n",
    "class TrainingCallback(BaseCallback):\n",
    "    def __init__(self, env, verbose=1):\n",
    "        super(TrainingCallback, self).__init__(verbose)\n",
    "        self.env = env\n",
    "\n",
    "    def _on_step(self) -> bool:\n",
    "        return True\n",
    "\n",
    "    def _on_rollout_start(self) -> None:\n",
    "        self.env.reset()\n",
    "\n",
    "    def _on_training_end(self):\n",
    "        print(\"Entrenamiento finalizado. Cerrando el entorno...\")\n",
    "        self.env.close()\n",
    "\n",
    "callback = TrainingCallback(env=env)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-09T12:40:05.474485200Z",
     "start_time": "2024-11-09T12:40:05.463482300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to ./logs/ppo_training/\n",
      "retrainning\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 16   |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 254  |\n",
      "|    total_timesteps | 4096 |\n",
      "-----------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 509         |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.031837076 |\n",
      "|    clip_fraction        | 0.209       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -33.8       |\n",
      "|    explained_variance   | 0.424       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 3.67        |\n",
      "|    n_updates            | 710         |\n",
      "|    policy_gradient_loss | 0.011       |\n",
      "|    std                  | 1.18e+03    |\n",
      "|    value_loss           | 24.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 769         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030486748 |\n",
      "|    clip_fraction        | 0.222       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -34.2       |\n",
      "|    explained_variance   | 0.5         |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 4.53        |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | 0.0131      |\n",
      "|    std                  | 1.29e+03    |\n",
      "|    value_loss           | 18.6        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 1027        |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033869326 |\n",
      "|    clip_fraction        | 0.197       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -34.5       |\n",
      "|    explained_variance   | 0.49        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 8.61        |\n",
      "|    n_updates            | 730         |\n",
      "|    policy_gradient_loss | 0.00714     |\n",
      "|    std                  | 1.42e+03    |\n",
      "|    value_loss           | 22          |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 15         |\n",
      "|    iterations           | 5          |\n",
      "|    time_elapsed         | 1290       |\n",
      "|    total_timesteps      | 20480      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.03123317 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -35        |\n",
      "|    explained_variance   | 0.494      |\n",
      "|    learning_rate        | 0.001      |\n",
      "|    loss                 | 8.61       |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | 0.0113     |\n",
      "|    std                  | 1.56e+03   |\n",
      "|    value_loss           | 21.2       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 1555        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.037199475 |\n",
      "|    clip_fraction        | 0.264       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -35.3       |\n",
      "|    explained_variance   | 0.467       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 4.66        |\n",
      "|    n_updates            | 750         |\n",
      "|    policy_gradient_loss | 0.0101      |\n",
      "|    std                  | 1.72e+03    |\n",
      "|    value_loss           | 23.2        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 1816        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029669166 |\n",
      "|    clip_fraction        | 0.2         |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -35.7       |\n",
      "|    explained_variance   | 0.448       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 3.32        |\n",
      "|    n_updates            | 760         |\n",
      "|    policy_gradient_loss | 0.0134      |\n",
      "|    std                  | 1.88e+03    |\n",
      "|    value_loss           | 22.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 2076        |\n",
      "|    total_timesteps      | 32768       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028722554 |\n",
      "|    clip_fraction        | 0.18        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -36.1       |\n",
      "|    explained_variance   | 0.363       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 5.8         |\n",
      "|    n_updates            | 770         |\n",
      "|    policy_gradient_loss | 0.0104      |\n",
      "|    std                  | 2.06e+03    |\n",
      "|    value_loss           | 22.8        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 2338        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.044027105 |\n",
      "|    clip_fraction        | 0.319       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -36.5       |\n",
      "|    explained_variance   | 0.492       |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 2.85        |\n",
      "|    n_updates            | 780         |\n",
      "|    policy_gradient_loss | 0.0121      |\n",
      "|    std                  | 2.29e+03    |\n",
      "|    value_loss           | 17.7        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 2598        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.034417547 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -36.9       |\n",
      "|    explained_variance   | 0.37        |\n",
      "|    learning_rate        | 0.001       |\n",
      "|    loss                 | 12.6        |\n",
      "|    n_updates            | 790         |\n",
      "|    policy_gradient_loss | 0.0177      |\n",
      "|    std                  | 2.51e+03    |\n",
      "|    value_loss           | 23.1        |\n",
      "-----------------------------------------\n",
      "Entrenamiento finalizado. Cerrando el entorno...\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.logger import configure\n",
    "\n",
    "\n",
    "timesteps = 40960 #define los asos totales que se usarán para entrenar al modelo\n",
    "log_dir = \"./logs/\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "new_logger = configure(log_dir, [\"stdout\", \"csv\", \"log\"])\n",
    "\n",
    "if not os.path.exists('./models/ppomodel.zip'):\n",
    "    print(\"first train\")\n",
    "\n",
    "    model = PPO(\n",
    "        \"MultiInputPolicy\",\n",
    "        env,\n",
    "        verbose=1,          # Si quiero ver las acciones por terminal\n",
    "        n_steps=1024,       # Controla el buffer de experiencias para actualizar la política\n",
    "        batch_size=64,      # Tamaño del lote, separa el buffer de experiencias en paquetes de este tamaño\n",
    "        learning_rate=1e-3, # Tasa de aprendizaje\n",
    "        ent_coef=0.2       # Coeficiente de entropía para exploración\n",
    "    )\n",
    "    model.set_logger(new_logger)\n",
    "    model.learn(total_timesteps=timesteps, callback=callback)\n",
    "    model.save('./models/ppomodel')\n",
    "else:\n",
    "    print(\"retrainning\")\n",
    "\n",
    "    model = PPO.load(\"./models/ppomodel.zip\", env=env)\n",
    "\n",
    "    model.set_logger(new_logger)\n",
    "\n",
    "    model.learn(total_timesteps=timesteps, callback=callback)\n",
    "    model.save(path=\"./models/ppomodel\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-09T13:23:44.033218Z",
     "start_time": "2024-11-09T12:40:05.475481600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo copiado y renombrado a ./data_collected/ppo20241109_142344.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def move_and_rename_csv(src_dir, dst_dir, new_name):\n",
    "    # Buscar el archivo CSV en el directorio fuente\n",
    "    csv_files = [f for f in os.listdir(src_dir) if f.endswith('.csv')]\n",
    "\n",
    "    # Verificar si hay algún archivo CSV en el directorio de origen\n",
    "    if not csv_files:\n",
    "        print(\"No se encontró ningún archivo CSV en el directorio de origen.\")\n",
    "        return\n",
    "\n",
    "    # Tomar el primer archivo CSV encontrado\n",
    "    csv_file = csv_files[0]\n",
    "    src_path = os.path.join(src_dir, csv_file)\n",
    "    dst_path = os.path.join(dst_dir, new_name)\n",
    "\n",
    "    # Mover y renombrar el archivo\n",
    "    shutil.copy2(src_path, dst_path)\n",
    "    print(f\"Archivo copiado y renombrado a {dst_path}\")\n",
    "\n",
    "\n",
    "src_directory = log_dir\n",
    "dst_directory = './data_collected/'\n",
    "new_filename = f'ppo{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "\n",
    "move_and_rename_csv(src_directory, dst_directory, new_filename)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-09T13:23:44.049218800Z",
     "start_time": "2024-11-09T13:23:44.038220400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "init = make_env()\n",
    "env = init()\n",
    "observation, _ = env.reset()\n",
    "\n",
    "for i in range(100):\n",
    "    action, _states = model.predict(observation, deterministic=True)\n",
    "    observation, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "    if terminated:\n",
    "        observation, _ = env.reset()\n",
    "\n",
    "env.close()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
